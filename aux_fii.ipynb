{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f8b3c2",
   "metadata": {},
   "source": [
    "# Gera√ß√£o da Tabela Base de Origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ffebaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:128: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(html)[0]\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:150: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['P/VP'] = df['P/VP'] / 100\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Liquidez Di√°ria (R$)'] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Patrim√¥nio L√≠quido'] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Num. Cotistas'] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Pre√ßo Atual (R$)'] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['√öltimo Dividendo'] = (\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_5428\\522615446.py:196: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\n"
     ]
    }
   ],
   "source": [
    "# Esse processo preciso rodar diariamente e localmente\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import streamlit as st\n",
    "\n",
    "def get_fii_table():\n",
    "    url = \"https://www.fundsexplorer.com.br/ranking\"\n",
    "\n",
    "    options = Options()\n",
    "    # options.add_argument(\"--headless=new\")\n",
    "    # options.add_argument(\"--no-sandbox\")\n",
    "    # options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # espera inicial\n",
    "\n",
    "        # --- 0) Tenta fechar/aceitar o cookie banner por v√°rios caminhos ---\n",
    "        cookie_selectors = [\n",
    "            'button[data-test=\"accept\"]',\n",
    "            'button#hs-eu-confirmation-button',             # exemplos comuns\n",
    "            'button[aria-label*=\"aceitar\"]',\n",
    "            'button:contains(\"Aceitar\")',                   # fallback textual (pode n√£o funcionar no CSS)\n",
    "            'div#hs-en-cookie-confirmation-buttons-area button',\n",
    "            'button:contains(\"Aceitar todos\")'\n",
    "        ]\n",
    "        # tentar por texto tamb√©m (mais confi√°vel)\n",
    "        texts_to_try = [\"Aceitar todos\", \"Aceitar\", \"OK\", \"Fechar\"]\n",
    "\n",
    "        # 1) tentar clique por seletores diretos\n",
    "        for sel in cookie_selectors:\n",
    "            try:\n",
    "                els = driver.find_elements(By.CSS_SELECTOR, sel)\n",
    "                if els:\n",
    "                    for e in els:\n",
    "                        try:\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView(true);\", e)\n",
    "                            driver.execute_script(\"arguments[0].click();\", e)\n",
    "                            time.sleep(0.4)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    # se algum bot√£o foi clicado, pausa e tenta prosseguir\n",
    "                    time.sleep(0.6)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # 2) tentar clicar por texto (procura por bot√µes/links)\n",
    "        for txt in texts_to_try:\n",
    "            try:\n",
    "                candidates = driver.find_elements(By.XPATH, f\"//button[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{txt.lower()}') or //a[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{txt.lower()}')]]\")\n",
    "                if candidates:\n",
    "                    for c in candidates:\n",
    "                        try:\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView(true);\", c)\n",
    "                            driver.execute_script(\"arguments[0].click();\", c)\n",
    "                            time.sleep(0.4)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    time.sleep(0.6)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # 3) se ainda existir o elemento de cookie conhecido, remove via JS (for√ßado)\n",
    "        try:\n",
    "            driver.execute_script(\"\"\"\n",
    "                var el = document.getElementById('hs-en-cookie-confirmation-buttons-area');\n",
    "                if (el) { el.remove(); }\n",
    "                var el2 = document.querySelector('[id^=hs-en-cookie]'); if(el2) el2.remove();\n",
    "                var overlays = document.querySelectorAll('.cookie, .cookies, .hs-cookie-banner'); \n",
    "                overlays.forEach(e => e.remove());\n",
    "            \"\"\")\n",
    "            time.sleep(0.4)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # --- 4) abrir o menu de colunas (scroll + click via JS para evitar intercept) ---\n",
    "        botao_colunas = wait.until(EC.presence_of_element_located((By.ID, \"colunas-ranking__select-button\")))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", botao_colunas)\n",
    "        try:\n",
    "            # preferencial: click via JS para evitar intercept\n",
    "            driver.execute_script(\"arguments[0].click();\", botao_colunas)\n",
    "        except Exception:\n",
    "            # fallback: webdriver click\n",
    "            botao_colunas.click()\n",
    "        time.sleep(0.6)\n",
    "\n",
    "        # --- 5) clicar em \"todos\" (label) ---\n",
    "        label_todos = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'label[for=\"colunas-ranking__todos\"]')))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", label_todos)\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", label_todos)\n",
    "        except Exception:\n",
    "            label_todos.click()\n",
    "        time.sleep(1.0)  # deixa o JS atualizar a tabela\n",
    "\n",
    "        # --- 6) esperar a tabela estar populada ---\n",
    "        def tabela_populada(driver):\n",
    "            try:\n",
    "                rows = driver.find_elements(By.CSS_SELECTOR, \".default-fiis-table__container__table tbody tr\")\n",
    "                # contar linhas n√£o-vazias\n",
    "                count = 0\n",
    "                for r in rows:\n",
    "                    tds = r.find_elements(By.TAG_NAME, \"td\")\n",
    "                    if any(td.text.strip() for td in tds):\n",
    "                        count += 1\n",
    "                return count > 5  # ajuste se precisar\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        wait.until(tabela_populada)\n",
    "\n",
    "        # --- 7) pegar HTML da tabela ---\n",
    "        tabela = driver.find_element(By.CSS_SELECTOR, \".default-fiis-table__container__table\")\n",
    "        html = tabela.get_attribute(\"outerHTML\")\n",
    "        df = pd.read_html(html)[0]\n",
    "        return df\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "#Call the function to test\n",
    "df_fiis = get_fii_table()\n",
    "\n",
    "def carregar_dados(df=df_fiis):\n",
    "\n",
    "    df = df.dropna(subset=[\n",
    "        'P/VP',\n",
    "        'DY (3M) Acumulado',\n",
    "        'DY (6M) Acumulado',\n",
    "        'DY (12M) Acumulado',\n",
    "        'Liquidez Di√°ria (R$)',\n",
    "        'Patrim√¥nio L√≠quido',\n",
    "        'Num. Cotistas',\n",
    "        'Pre√ßo Atual (R$)'\n",
    "    ])\n",
    "\n",
    "    df['P/VP'] = df['P/VP'] / 100\n",
    "\n",
    "    for col in ['DY (3M) Acumulado', 'DY (6M) Acumulado', 'DY (12M) Acumulado']:\n",
    "        df[col] = (\n",
    "            df[col].astype(str)\n",
    "            .str.replace('%', '', regex=False)\n",
    "            .str.replace('.', '', regex=False)\n",
    "            .str.replace(',', '.', regex=False)\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "    df['Liquidez Di√°ria (R$)'] = (\n",
    "        df['Liquidez Di√°ria (R$)']\n",
    "        .astype(str).str.replace('.', '', regex=False)\n",
    "        .str.replace(',', '.', regex=False)\n",
    "        .astype(float) / 1_000_000\n",
    "    )\n",
    "\n",
    "    df['Patrim√¥nio L√≠quido'] = (\n",
    "        df['Patrim√¥nio L√≠quido']\n",
    "        .astype(str).str.replace('.', '', regex=False)\n",
    "        .str.replace(',', '.', regex=False)\n",
    "        .astype(float) / 1_000_000\n",
    "    )\n",
    "\n",
    "    df['Num. Cotistas'] = (\n",
    "        df['Num. Cotistas']\n",
    "        .astype(str).str.replace('.', '', regex=False)\n",
    "        .str.replace(',', '.', regex=False)\n",
    "        .astype(float) / 1_000\n",
    "    )\n",
    "\n",
    "    df['Pre√ßo Atual (R$)'] = (\n",
    "        df['Pre√ßo Atual (R$)']\n",
    "        .astype(str).str.replace('.', '', regex=False)\n",
    "        .str.replace(',', '.', regex=False)\n",
    "        .astype(float) / 100\n",
    "    )\n",
    "\n",
    "    df['√öltimo Dividendo'] = (\n",
    "        df['√öltimo Dividendo']\n",
    "        .astype(str).str.replace('.', '', regex=False)\n",
    "        .str.replace(',', '.', regex=False)\n",
    "        .astype(float) / 100\n",
    "    )\n",
    "\n",
    "    df.rename(columns={\n",
    "        'Liquidez Di√°ria (R$)': 'Liquidez Di√°ria (milh√µes R$)',\n",
    "        'Patrim√¥nio L√≠quido': 'Patrim√¥nio L√≠quido (milh√µes R$)',\n",
    "        'Num. Cotistas': 'Num. Cotistas (milhares)'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_fiis = carregar_dados(df_fiis)\n",
    "today_str = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "ajustes_manuais_segmento = pd.read_csv('ajustes_manuais_segmento.csv')\n",
    "\n",
    "df_fiis = df_fiis.merge(ajustes_manuais_segmento, on='Fundos', how='left', suffixes=('', '_novo'))\n",
    "df_fiis['Setor'] = df_fiis['Setor_novo'].combine_first(df_fiis['Setor'])\n",
    "df_fiis.drop(columns=['Setor_novo'], inplace=True)\n",
    "\n",
    "# Salvando os Top 10 FIIs Descontados com Qualidade\n",
    "def filtrar_fiis_descontados_com_qualidade(df):\n",
    "    filtros = (\n",
    "        (df[\"P/VP\"] >= 0.85) &\n",
    "        (df[\"P/VP\"] < 1.0) &\n",
    "        (df[\"DY (3M) Acumulado\"] >= 3) &\n",
    "        (df[\"DY (6M) Acumulado\"] >= 6) &\n",
    "        (df[\"DY (12M) Acumulado\"] >= 12) &\n",
    "        (df[\"Liquidez Di√°ria (milh√µes R$)\"] >= 1) &\n",
    "        (df[\"Patrim√¥nio L√≠quido (milh√µes R$)\"] >= 500) &\n",
    "        (df[\"Num. Cotistas (milhares)\"] >= 10)\n",
    "    )\n",
    "    return df[filtros].copy()\n",
    "\n",
    "df_filtrados = filtrar_fiis_descontados_com_qualidade(df_fiis)\n",
    "\n",
    "df_top10 = (\n",
    "    df_filtrados\n",
    "    .sort_values(\"DY (12M) Acumulado\", ascending=False)\n",
    "    .head(10)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ARCT11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$ASMT11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BBFI11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BICR11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BLMC11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$BLMR11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$BPRP11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BREV11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$BRIX11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BRLA11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$BTCR11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$CCRF11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$CIXM11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$COPP11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$CXCE11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$DAMT11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$DRIT11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$EDFO11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$FAMB11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$FIIP11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$GURB11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$HBRH11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$IDFI11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$KINP11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$LGCP11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$LUGG11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MALL11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MATV11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$MCHF11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MCHY11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MFAI11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MGFF11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MGLG11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MINT11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$MORE11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$NCHB11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$OGHY11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$ORPD11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$PLOG11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$PRTS11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$QAGR11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$QAMI11.SA: possibly delisted; no price data found  (period=1y)\n",
      "$QIRI11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$RBVO11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$SIGR11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$VLOL11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$VSEC11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$WTSP11B.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$XPPR11.SA: possibly delisted; no price data found  (period=1y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from glob import glob\n",
    "\n",
    "dfs = glob('df_fiis/df_fiis*')\n",
    "lim = 0\n",
    "\n",
    "# ==========================\n",
    "# PAR√ÇMETROS\n",
    "# ==========================\n",
    "PVP_MIN = 0.85\n",
    "PVP_MAX = 1.00\n",
    "LIQUIDEZ_MIN = 1.0      # R$ mi/dia\n",
    "JANELA_QUEDA = 10\n",
    "CDI = 0.15\n",
    "SELIC_ANUAL = (1 + CDI) * (1 - 0.225)\n",
    "PATRIMONIO_MIN = 500  # R$ 500 mi\n",
    "NUM_COTISTAS_MIN = 10_000\n",
    "DY_3M_MIN = 3\n",
    "DY_6M_MIN = 6\n",
    "DY_12M_MIN = 12\n",
    "\n",
    "coluna_score = []\n",
    "coluna_bloqueios = []\n",
    "coluna_motivos = []\n",
    "fiis_base = []\n",
    "\n",
    "colunas_utilizadas = [\n",
    "    'Fundos', 'Setor', 'Pre√ßo Atual (R$)', 'Liquidez Di√°ria (milh√µes R$)',\n",
    "    'P/VP', '√öltimo Dividendo', 'Dividend Yield', 'DY (3M) Acumulado',\n",
    "    'DY (6M) Acumulado', 'DY (12M) Acumulado', 'DY Ano',\n",
    "    'Patrim√¥nio L√≠quido (milh√µes R$)', 'Quant. Ativos',\n",
    "    'Num. Cotistas (milhares)'\n",
    "]\n",
    "\n",
    "df_fiis = df_fiis[colunas_utilizadas]\n",
    "\n",
    "for i in df_fiis.Fundos.unique():\n",
    "    try:\n",
    "        ticker = yf.Ticker(f\"{i}.SA\")\n",
    "        hist = ticker.history(period=\"1y\")\n",
    "\n",
    "        if len(hist) < 200:\n",
    "            raise ValueError(\"Hist√≥rico insuficiente\")\n",
    "\n",
    "        retornos = hist[\"Close\"].pct_change()\n",
    "\n",
    "        # =====================================================\n",
    "        # üî• CRIT√âRIO DE VOLATILIDADE / EVENTO AT√çPICO (AJUSTADO)\n",
    "        # =====================================================\n",
    "        retorno_10d = (1 + retornos).rolling(JANELA_QUEDA).apply(\n",
    "            lambda x: x.prod() - 1,\n",
    "            raw=False\n",
    "        )\n",
    "\n",
    "        if pd.isna(retorno_10d.iloc[-1]):\n",
    "            raise ValueError(\"Hist√≥rico insuficiente para janela de 10 dias\")\n",
    "\n",
    "        retorno_10d_atual = retorno_10d.iloc[-1]\n",
    "        percentil_queda = (retorno_10d <= retorno_10d_atual).mean()\n",
    "\n",
    "        # =====================================================\n",
    "        score = 0\n",
    "        bloqueios = []\n",
    "        motivos = []\n",
    "\n",
    "        # P/VP\n",
    "        if PVP_MIN <= df_fiis[df_fiis[\"Fundos\"] == i][\"P/VP\"].iloc[0] <= PVP_MAX:\n",
    "            score += 1\n",
    "            motivos.append(\"‚úÖ Pre√ßo dentro da faixa saud√°vel\")\n",
    "        else:\n",
    "            bloqueios.append(\"‚ùå Pre√ßo fora da faixa saud√°vel\")\n",
    "\n",
    "        # Liquidez\n",
    "        if df_fiis[df_fiis[\"Fundos\"] == i][\"Liquidez Di√°ria (milh√µes R$)\"].iloc[0] >= LIQUIDEZ_MIN:\n",
    "            score += 1\n",
    "            motivos.append(\"‚úÖ Liquidez adequada para entrada e sa√≠da\")\n",
    "        else:\n",
    "            bloqueios.append(\"‚ùå Liquidez inadequada para opera√ß√£o segura\")\n",
    "\n",
    "        # Evento at√≠pico de curto prazo\n",
    "        if percentil_queda >= 0.15:\n",
    "            score += 1\n",
    "            motivos.append(\"‚úÖ Queda recente compat√≠vel com o hist√≥rico do ativo\")\n",
    "        else:\n",
    "            bloqueios.append(\"‚ùå Queda recente at√≠pica vs hist√≥rico do ativo\")\n",
    "\n",
    "        # Patrim√¥nio\n",
    "        if df_fiis[df_fiis[\"Fundos\"] == i][\"Patrim√¥nio L√≠quido (milh√µes R$)\"].iloc[0] >= PATRIMONIO_MIN:\n",
    "            score += 1\n",
    "            motivos.append(\"‚úÖ Escala patrimonial adequada\")\n",
    "        else:\n",
    "            bloqueios.append(\"‚ùå Escala patrimonial abaixo do recomendado\")\n",
    "\n",
    "        # Cotistas\n",
    "        num_cotistas = df_fiis[df_fiis[\"Fundos\"] == i][\"Num. Cotistas (milhares)\"].iloc[0] * 1000\n",
    "        if num_cotistas >= NUM_COTISTAS_MIN:\n",
    "            score += 1\n",
    "            if num_cotistas >= 150_000:\n",
    "                motivos.append(\"‚úÖ Base de cotistas consolidada\")\n",
    "            else:\n",
    "                motivos.append(\"‚úÖ Base de cotistas adequada\")\n",
    "        else:\n",
    "            bloqueios.append(\"‚ùå Base de cotistas pouco representativa\")\n",
    "\n",
    "        # DY\n",
    "        if (\n",
    "            df_fiis[df_fiis[\"Fundos\"] == i][\"DY (3M) Acumulado\"].iloc[0] >= DY_3M_MIN\n",
    "            and df_fiis[df_fiis[\"Fundos\"] == i][\"DY (6M) Acumulado\"].iloc[0] >= DY_6M_MIN\n",
    "            and df_fiis[df_fiis[\"Fundos\"] == i][\"DY (12M) Acumulado\"].iloc[0] >= DY_12M_MIN\n",
    "        ):\n",
    "            score += 1\n",
    "            motivos.append(\"‚úÖ Distribui√ß√£o de rendimentos consistente\")\n",
    "        else:\n",
    "            bloqueios.append(\"‚ùå Distribui√ß√£o de rendimentos inconsistente\")\n",
    "\n",
    "        coluna_score.append(score)\n",
    "        coluna_bloqueios.append(bloqueios)\n",
    "        coluna_motivos.append(motivos)\n",
    "        fiis_base.append(i)\n",
    "\n",
    "    except Exception as e:\n",
    "        coluna_score.append(0)\n",
    "        coluna_bloqueios.append([\"Informa√ß√£o insuficiente\"])\n",
    "        coluna_motivos.append([str(e)])\n",
    "        fiis_base.append(i)\n",
    "\n",
    "df_fiis = df_fiis[colunas_utilizadas]\n",
    "df_fiis = df_fiis.drop_duplicates()\n",
    "df_fiis['Motivos'] = coluna_motivos\n",
    "df_fiis['Bloqueios'] = coluna_bloqueios\n",
    "df_fiis['Score'] = coluna_score\n",
    "\n",
    "df_fiis.to_parquet(f'df_fiis/df_fiis.parquet', index=False)\n",
    "df_fiis.to_parquet(f'C:/Users/danie/OneDrive/Documentos/Refera_Django/refera_app/data/df_fiis.parquet', index=False)\n",
    "df_fiis.to_parquet(f'df_fiis/df_fiis_{today_str}.parquet', index=False)\n",
    "\n",
    "\n",
    "# df_top10.to_parquet(f'hist_top10/hist_top10_{today_str}.parquet', index=False)\n",
    "# df_top10.to_parquet(f'hist_top10/df_top10.parquet', index=False)\n",
    "# df_top10.to_parquet(f'C:/Users/danie/OneDrive/Documentos/Refera_Django/refera_app/data/df_top10.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eabd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fiis.to_parquet(f'df_fiis/df_fiis.parquet', index=False)\n",
    "df_fiis.to_parquet(f'C:/Users/danie/OneDrive/Documentos/Refera_Django/refera_app/data/df_fiis.parquet', index=False)\n",
    "df_fiis.to_parquet(f'df_fiis/df_fiis_{today_str}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8841df",
   "metadata": {},
   "source": [
    "# Construindo a base completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abe479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.read_parquet('df_fiis/base_completa_df_fiis.parquet')\n",
    "# x['data'] = '2025-12-21'\n",
    "# x.to_parquet('df_fiis/base_completa_df_fiis.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fd455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-21 j√° inserida\n",
      "2025-12-22 j√° inserida\n",
      "2025-12-29 j√° inserida\n",
      "2025-12-30 j√° inserida\n",
      "2026-01-03 j√° inserida\n",
      "2026-01-04 j√° inserida\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2025-12-21', '2025-12-22', '2025-12-29', '2025-12-30',\n",
       "       '2026-01-03', '2026-01-04'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "dfs = glob('df_fiis/df_fiis_*')\n",
    "df_inicial = pd.read_parquet('df_fiis/base_completa_df_fiis.parquet')\n",
    "datas_ja_inseridas = df_inicial.data.unique()\n",
    "\n",
    "for i in dfs:\n",
    "    data = i.split('.')[0].split('_')[-1]\n",
    "    if data not in datas_ja_inseridas:\n",
    "        print('Inserindo :',data)\n",
    "        df_data = pd.read_parquet(i)\n",
    "        df_data['data'] = data\n",
    "        df_inicial = pd.concat([df_inicial,df_data])   \n",
    "    else:\n",
    "        print(data,'j√° inserida')\n",
    "\n",
    "df_inicial.to_parquet('df_fiis/base_completa_df_fiis.parquet')\n",
    "df_inicial.data.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480db0",
   "metadata": {},
   "source": [
    "# Pegando os melhores e pegando os que n√£o passam no crit√©rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47f21b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfeitos : (24, 17)\n",
      "Bons : (79, 17)\n",
      "Obs : (67, 17)\n",
      "Ruins : (288, 17)\n"
     ]
    }
   ],
   "source": [
    "#lendo o arquivo mais atual \n",
    "from glob import glob\n",
    "dfs = glob('df_fiis/df_fiis_*')\n",
    "\n",
    "ultimo_arquivo = dfs[-1]\n",
    "ultimo_arquivo = 'df_fiis/df_fiis.parquet'\n",
    "\n",
    "base_atual = pd.read_parquet(ultimo_arquivo)\n",
    "\n",
    "score_perfeitos = base_atual[base_atual.Score == 6]\n",
    "score_bons = base_atual[(base_atual.Score >= 4) & (base_atual.Score < 6)]\n",
    "score_obs = base_atual[(base_atual.Score == 3)]\n",
    "score_ruins = base_atual[(base_atual.Score <= 2)]\n",
    "\n",
    "print('Perfeitos :',score_perfeitos.shape)\n",
    "print('Bons :',score_bons.shape)\n",
    "print('Obs :',score_obs.shape)\n",
    "print('Ruins :',score_ruins.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b657c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score\n",
       "6    24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_perfeitos.value_counts('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061f2d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BTCI11', 'BTHF11', 'CPSH11', 'CPTS11', 'GGRC11', 'HGCR11',\n",
       "       'JSAF11', 'KNCA11', 'KNHF11', 'KNSC11', 'MCCI11', 'MCRE11',\n",
       "       'RBRX11', 'RBRY11', 'RECR11', 'RURA11', 'RZAG11', 'RZAK11',\n",
       "       'RZTR11', 'TGAR11', 'VCJR11', 'VGIR11', 'VRTA11', 'XPCI11'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_perfeitos.Fundos.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32e0a7",
   "metadata": {},
   "source": [
    "# Alerta de P/VP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "797c44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_completa = pd.read_parquet('df_fiis/base_completa_df_fiis.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8ec0b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAZQ11 o pvp era 1.01 e agora √©  0.99\n",
      "BTYU11 o pvp era 1.0 e agora √©  0.92\n",
      "HGCR11 o pvp era 1.0 e agora √©  0.99\n",
      "HPDP11 o pvp era 1.0 e agora √©  0.99\n",
      "KNSC11 o pvp era 1.0 e agora √©  0.99\n",
      "WPLZ11 o pvp era 1.01 e agora √©  0.93\n"
     ]
    }
   ],
   "source": [
    "# Preciso comparar um dia com o outro para ver os pvp\n",
    "dfs = glob('df_fiis/df_fiis_*')\n",
    "dia_anterior = dfs[-2].split('.')[0].split('_')[-1]\n",
    "dia_hoje =  dfs[-1].split('.')[0].split('_')[-1]\n",
    "\n",
    "# pegar o pvp dos fiis nesses dias \n",
    "\n",
    "for i in base_completa.Fundos.unique():\n",
    "    pvp_anterior = base_completa[(base_completa.data == dia_anterior) & (base_completa.Fundos == i)]['P/VP'].iloc[0]\n",
    "    pvp_atual = base_completa[(base_completa.data == dia_hoje) & (base_completa.Fundos == i)]['P/VP'].iloc[0]\n",
    "    if pvp_atual < 1 and pvp_anterior >= 1:\n",
    "        print(i, 'o pvp era', pvp_anterior,'e agora √© ',pvp_atual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0943136",
   "metadata": {},
   "source": [
    "# Pegando Historicos dos pre√ßos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff84dfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-02 00:00:00-03:00</th>\n",
       "      <td>88.575386</td>\n",
       "      <td>89.715807</td>\n",
       "      <td>87.102722</td>\n",
       "      <td>88.404770</td>\n",
       "      <td>166735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-03 00:00:00-03:00</th>\n",
       "      <td>88.404777</td>\n",
       "      <td>89.652950</td>\n",
       "      <td>87.066810</td>\n",
       "      <td>87.758247</td>\n",
       "      <td>160091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06 00:00:00-03:00</th>\n",
       "      <td>88.476607</td>\n",
       "      <td>89.078243</td>\n",
       "      <td>87.758238</td>\n",
       "      <td>88.656204</td>\n",
       "      <td>126403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07 00:00:00-03:00</th>\n",
       "      <td>88.656196</td>\n",
       "      <td>89.554163</td>\n",
       "      <td>88.162312</td>\n",
       "      <td>88.449661</td>\n",
       "      <td>111188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-08 00:00:00-03:00</th>\n",
       "      <td>88.674147</td>\n",
       "      <td>89.257827</td>\n",
       "      <td>87.102707</td>\n",
       "      <td>87.102707</td>\n",
       "      <td>126081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23 00:00:00-03:00</th>\n",
       "      <td>108.410004</td>\n",
       "      <td>108.900002</td>\n",
       "      <td>108.139999</td>\n",
       "      <td>108.900002</td>\n",
       "      <td>139850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-26 00:00:00-03:00</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.980003</td>\n",
       "      <td>108.180000</td>\n",
       "      <td>108.180000</td>\n",
       "      <td>153520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-29 00:00:00-03:00</th>\n",
       "      <td>109.269997</td>\n",
       "      <td>109.290001</td>\n",
       "      <td>107.839996</td>\n",
       "      <td>108.070000</td>\n",
       "      <td>131612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-30 00:00:00-03:00</th>\n",
       "      <td>108.529999</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>108.059998</td>\n",
       "      <td>108.059998</td>\n",
       "      <td>124253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-02 00:00:00-03:00</th>\n",
       "      <td>109.150002</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>108.620003</td>\n",
       "      <td>108.900002</td>\n",
       "      <td>117002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2025-01-02 00:00:00-03:00   88.575386   89.715807   87.102722   88.404770   \n",
       "2025-01-03 00:00:00-03:00   88.404777   89.652950   87.066810   87.758247   \n",
       "2025-01-06 00:00:00-03:00   88.476607   89.078243   87.758238   88.656204   \n",
       "2025-01-07 00:00:00-03:00   88.656196   89.554163   88.162312   88.449661   \n",
       "2025-01-08 00:00:00-03:00   88.674147   89.257827   87.102707   87.102707   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-12-23 00:00:00-03:00  108.410004  108.900002  108.139999  108.900002   \n",
       "2025-12-26 00:00:00-03:00  109.000000  109.980003  108.180000  108.180000   \n",
       "2025-12-29 00:00:00-03:00  109.269997  109.290001  107.839996  108.070000   \n",
       "2025-12-30 00:00:00-03:00  108.529999  109.000000  108.059998  108.059998   \n",
       "2026-01-02 00:00:00-03:00  109.150002  109.199997  108.620003  108.900002   \n",
       "\n",
       "                           Volume  Dividends  Stock Splits  \n",
       "Date                                                        \n",
       "2025-01-02 00:00:00-03:00  166735        0.0           0.0  \n",
       "2025-01-03 00:00:00-03:00  160091        0.0           0.0  \n",
       "2025-01-06 00:00:00-03:00  126403        0.0           0.0  \n",
       "2025-01-07 00:00:00-03:00  111188        0.0           0.0  \n",
       "2025-01-08 00:00:00-03:00  126081        0.0           0.0  \n",
       "...                           ...        ...           ...  \n",
       "2025-12-23 00:00:00-03:00  139850        0.0           0.0  \n",
       "2025-12-26 00:00:00-03:00  153520        0.0           0.0  \n",
       "2025-12-29 00:00:00-03:00  131612        0.0           0.0  \n",
       "2025-12-30 00:00:00-03:00  124253        0.0           0.0  \n",
       "2026-01-02 00:00:00-03:00  117002        0.0           0.0  \n",
       "\n",
       "[251 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ticker = yf.Ticker(\"XPML11.SA\")\n",
    "hist = ticker.history(period=\"12mo\")  # ou \"3mo\", \"6mo\", \"1y\"\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a84023",
   "metadata": {},
   "source": [
    "# Envio por whatsapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a73c4e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wa.me/5513981832920?text=Opa%20Boa%20noite%21%20Tudo%20bem%2C%20Daniel%3F%20Voc%C3%AA%20pediu%20para%20eu%20validar%20os%20seguintes%20%3A%20CACR11%2C%20HGLG11%0ACACR11%20%3A%201%2C74%20%25%20%0AQualquer%20d%C3%BAvida%20estou%20%C3%A0%20disposi%C3%A7%C3%A3o%21\n",
      "https://wa.me/5527998976226?text=Opa%20Boa%20noite%21%20Tudo%20bem%2C%20Esther%3F%20Voc%C3%AA%20pediu%20para%20eu%20validar%20os%20seguintes%20%3A%20XPML11%2C%20BTAL11%0AXPML11%20%3A%200%2C86%20%25%20%0AQualquer%20d%C3%BAvida%20estou%20%C3%A0%20disposi%C3%A7%C3%A3o%21\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pyautogui\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(r\"--user-data-dir=C:\\selenium\\chrome_profile_whatsapp\")\n",
    "options.add_argument(\"--profile-directory=Default\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "numero = \"5513981832920\"\n",
    "mensagem = \"Ol√°! Tudo bem? Teste FII.\"\n",
    "\n",
    "lista_usuarios = {\n",
    "    \"5513981832920\" : ['Daniel','CACR11', 'HGLG11'],\n",
    "    \"5527998976226\" : ['Esther','XPML11', 'BTAL11']\n",
    "}\n",
    "time.sleep(10)\n",
    "for numero in lista_usuarios.keys():\n",
    "    mensagem = f'''Opa Boa noite! Tudo bem, {lista_usuarios[numero][0]}? Voc√™ pediu para eu validar os seguintes : {', '.join(lista_usuarios[numero][1:])}\\n{lista_usuarios[numero][1]} : {df_fiis[df_fiis['Fundos'] == lista_usuarios[numero][1]]['Dividend Yield'].iloc[0]} \\nQualquer d√∫vida estou √† disposi√ß√£o!'''\n",
    "    link = f\"https://wa.me/{numero}?text={urllib.parse.quote(mensagem)}\"\n",
    "    print(link)\n",
    "    # Abre o link do chat\n",
    "    driver.get(link)\n",
    "\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "\n",
    "    # Bot√£o \"Continuar para o chat\"\n",
    "    btn_continuar = wait.until(\n",
    "        EC.element_to_be_clickable(\n",
    "            (By.XPATH, \"/html/body/div[1]/div[1]/div[2]/div/section/div/div/div/div[2]/div[4]/a[2]/span\")\n",
    "        )\n",
    "    )\n",
    "    btn_continuar.click()\n",
    "    time.sleep(10)  # Espera o chat carregar\n",
    "    # Pressiona ENTER (envia a mensagem)\n",
    "    pyautogui.press(\"enter\")\n",
    "    time.sleep(1)\n",
    "    pyautogui.hotkey('ctrl', 'w')\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a13189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
